# pandas Ã— polars Ã— PySpark --- Comparativo PrÃ¡tico

Este repositÃ³rio contÃ©m um notebook de anÃ¡lise exploratÃ³ria usando um
dataset sintÃ©tico de varejo do Kaggle para comparar, na prÃ¡tica, como
executar as mesmas operaÃ§Ãµes em **pandas, polars e PySpark**.

## ğŸ¯ Objetivo

O objetivo principal Ã© ajudar analistas e engenheiros de dados a:

-   Entender que o raciocÃ­nio Ã© o mesmo, mesmo mudando a biblioteca\
-   Comparar sintaxes entre as trÃªs ferramentas\
-   Ver exemplos reais de uso em um mesmo dataset\
-   Desenvolver pensamento independente de engine

## ğŸ“‚ ConteÃºdo do repositÃ³rio

-   `notebook_pandas_polars_spark_retail.ipynb`\
    Notebook principal com anÃ¡lises equivalentes nas trÃªs bibliotecas.

## ğŸ“Š Dataset utilizado

Foi utilizado o dataset **RetailStoreProductSalesDataset.csv**, que
simula dados diÃ¡rios de varejo com variÃ¡veis como:

price, discount, promotion_intensity, footfall, ad_spend,
competitor_price, stock_level, weather_index, customer_sentiment e
return_rate.

O dataset possui 15.000 linhas e Ã© totalmente sintÃ©tico.

## ğŸ”§ Como rodar o projeto

1.  Clone este repositÃ³rio\

``` bash
git clone <URL_DO_SEU_REPO>
```

2.  Instale as dependÃªncias necessÃ¡rias\

``` bash
pip install pandas polars pyspark jupyter
```

3.  Abra o notebook\

``` bash
jupyter notebook
```

4.  Execute as cÃ©lulas na ordem.

## ğŸ§  O que vocÃª vai aprender

No notebook vocÃª verÃ¡ exemplos de:

-   Somar colunas\
-   Filtrar dados\
-   Contar valores\
-   Contar distintos\
-   Agrupar e agregar\
-   Transformar colunas em linhas\
-   EstatÃ­sticas descritivas\
-   Criar novas colunas\
-   Remover colunas

Tudo isso feito em **pandas, polars e PySpark** lado a lado.

## ğŸ¤ ContribuiÃ§Ãµes

SugestÃµes e melhorias sÃ£o bem-vindas.\
Sinta-se Ã  vontade para abrir issues ou pull requests.
